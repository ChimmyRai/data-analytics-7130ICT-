{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B8nKJ4hX_p1"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jTAwYn1X_p5"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih3xA-hYX_p6"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHTMFsIqX_p6",
        "outputId": "5b2aa8e0-20bd-4754-9157-5b24a8b35c64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "# X_test = ...\n",
        "# y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UararUiPX_p8"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDGVBDF-X_p8"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "CDuFatrZX_p8",
        "outputId": "cf7c69bb-f01d-408b-961f-80cd163299ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXg46GP_X_p9"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoUamWjPX_p9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVG9sjcrX_p9"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCtIHFnoX_p-",
        "outputId": "4ea16157-611b-412d-ae58-d3c21073e46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes=10)\n",
        "y_test_cat =  to_categorical(y_test,num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        " \n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0],np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0],np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxRaz97wX_p-"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I99xXxRUX_p-",
        "outputId": "0dd44ca1-15fb-448e-e7c3-dd3e44374e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10,input_dim=input_dim,activation=\"sigmoid\"))\n",
        "    model.add(Dense(10 ,activation=\"sigmoid\"))\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aj4bZBPX_p_"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O838tQmTX_p_",
        "outputId": "04daf2d3-f604-47af-aefb-b5d2fa2cde7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 2ms/step - loss: 1.9190 - accuracy: 0.3361\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.4088 - accuracy: 0.6091\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.1183 - accuracy: 0.6783\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9054 - accuracy: 0.7559\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7419 - accuracy: 0.7876\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.7991\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5862 - accuracy: 0.8064\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.8132\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.8224\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8344\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4789 - accuracy: 0.8406\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.8454\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.8483\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8510\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8527\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4233 - accuracy: 0.8558\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8572\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8593\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.8601\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8627\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8630\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3941 - accuracy: 0.8642\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3908 - accuracy: 0.8654\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3876 - accuracy: 0.8671\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3848 - accuracy: 0.8676\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3827 - accuracy: 0.8685\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8694\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3776 - accuracy: 0.8694\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3745 - accuracy: 0.8708\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3731 - accuracy: 0.8713\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3709 - accuracy: 0.8721\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3684 - accuracy: 0.8726\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8730\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8739\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8740\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8752\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8762\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.8761\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8767\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8763\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8769\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8782\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3499 - accuracy: 0.8787\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3495 - accuracy: 0.8793\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8786\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8797\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8798\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8802\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8806\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8809\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8808\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8826\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3381 - accuracy: 0.8826\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8838\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8828\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8823\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8834\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8840\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8846\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8836\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8835\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8848\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8855\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8852\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8865\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8856\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8869\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8864\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8861\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8874\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8874\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.8882\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8877\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3219 - accuracy: 0.8879\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8884\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8885\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3204 - accuracy: 0.8878\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.8904\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8891\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8888\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.8898\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8892\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8904\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8894\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3149 - accuracy: 0.8892\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8904\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8910\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3136 - accuracy: 0.8904\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3113 - accuracy: 0.8908\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8910\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8901\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8909\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8906\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.8917\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8918\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8923\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8928\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8925\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3091 - accuracy: 0.8910\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3069 - accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff01b19de10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYgDSF5X_p_"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2C9IWxFX_qA",
        "outputId": "2aa06750-b9a4-4af4-f0c4-6bfe212bc08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8934333324432373\n",
            "accuracy on test with NN: 0.8539999723434448\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvZrhTBYX_qA"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1-fH8ytX_qA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfx_7r2wX_qB"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mDCeBFHsX_qB"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9) \n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SxFaF1fX_qB",
        "outputId": "cfbe4ed2-dc87-4b04-8773-ddd0eea1e482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8626\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2VfEBNHX_qB"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvd83A-X_qC"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}