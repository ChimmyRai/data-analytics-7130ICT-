{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "12a40374-c669-43c6-8910-d11393d75813",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "0f1189cf-b5af-48f5-8c8e-2d68f0939afc",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8fae0f5-6dab-4c40-b56a-b896776ca3a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes=10)\n",
        "y_test_cat =  to_categorical(y_test,num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11072b7f-b64e-4a4e-8382-330453b099e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " c5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120,activation='relu', name=\"c5\" ))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84,activation='relu', name=\"F6\" ))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "6aabffb5-4f8f-47e0-b72d-3c828e35005d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 12s 31ms/step - loss: 1.6364 - accuracy: 0.4728 - val_loss: 0.9373 - val_accuracy: 0.6663\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.8120 - accuracy: 0.7000 - val_loss: 0.7486 - val_accuracy: 0.7222\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.7496 - val_loss: 0.6535 - val_accuracy: 0.7589\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6072 - accuracy: 0.7775 - val_loss: 0.6029 - val_accuracy: 0.7807\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.5572 - accuracy: 0.7959 - val_loss: 0.5496 - val_accuracy: 0.7991\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.5195 - accuracy: 0.8083 - val_loss: 0.5324 - val_accuracy: 0.8036\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.4998 - accuracy: 0.8177 - val_loss: 0.5106 - val_accuracy: 0.8144\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4841 - accuracy: 0.8221 - val_loss: 0.4926 - val_accuracy: 0.8192\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.4615 - accuracy: 0.8311 - val_loss: 0.4811 - val_accuracy: 0.8205\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4525 - accuracy: 0.8356 - val_loss: 0.4707 - val_accuracy: 0.8291\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4388 - accuracy: 0.8411 - val_loss: 0.4552 - val_accuracy: 0.8348\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8433 - val_loss: 0.4527 - val_accuracy: 0.8358\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4211 - accuracy: 0.8482 - val_loss: 0.4431 - val_accuracy: 0.8393\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.8504 - val_loss: 0.4428 - val_accuracy: 0.8373\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4060 - accuracy: 0.8543 - val_loss: 0.4318 - val_accuracy: 0.8430\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4059 - accuracy: 0.8526 - val_loss: 0.4324 - val_accuracy: 0.8426\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3947 - accuracy: 0.8583 - val_loss: 0.4235 - val_accuracy: 0.8451\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3873 - accuracy: 0.8608 - val_loss: 0.4117 - val_accuracy: 0.8490\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3801 - accuracy: 0.8637 - val_loss: 0.4142 - val_accuracy: 0.8495\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.8614 - val_loss: 0.4267 - val_accuracy: 0.8443\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3781 - accuracy: 0.8632 - val_loss: 0.3944 - val_accuracy: 0.8582\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8688 - val_loss: 0.3934 - val_accuracy: 0.8576\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3694 - accuracy: 0.8653 - val_loss: 0.3931 - val_accuracy: 0.8591\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8693 - val_loss: 0.3871 - val_accuracy: 0.8605\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3579 - accuracy: 0.8713 - val_loss: 0.3997 - val_accuracy: 0.8532\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3545 - accuracy: 0.8705 - val_loss: 0.3840 - val_accuracy: 0.8625\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3482 - accuracy: 0.8738 - val_loss: 0.3780 - val_accuracy: 0.8637\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3426 - accuracy: 0.8763 - val_loss: 0.3787 - val_accuracy: 0.8647\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3396 - accuracy: 0.8778 - val_loss: 0.3791 - val_accuracy: 0.8608\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3400 - accuracy: 0.8761 - val_loss: 0.3731 - val_accuracy: 0.8642\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3374 - accuracy: 0.8777 - val_loss: 0.3895 - val_accuracy: 0.8556\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3396 - accuracy: 0.8760 - val_loss: 0.3667 - val_accuracy: 0.8686\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3283 - accuracy: 0.8820 - val_loss: 0.3755 - val_accuracy: 0.8612\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3287 - accuracy: 0.8811 - val_loss: 0.3599 - val_accuracy: 0.8729\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3309 - accuracy: 0.8779 - val_loss: 0.3590 - val_accuracy: 0.8718\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.3231 - accuracy: 0.8834 - val_loss: 0.3609 - val_accuracy: 0.8700\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3234 - accuracy: 0.8829 - val_loss: 0.3575 - val_accuracy: 0.8705\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3170 - accuracy: 0.8853 - val_loss: 0.3533 - val_accuracy: 0.8737\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3143 - accuracy: 0.8868 - val_loss: 0.3528 - val_accuracy: 0.8743\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.3124 - accuracy: 0.8875 - val_loss: 0.3589 - val_accuracy: 0.8705\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3096 - accuracy: 0.8879 - val_loss: 0.3670 - val_accuracy: 0.8689\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3121 - accuracy: 0.8881 - val_loss: 0.3508 - val_accuracy: 0.8730\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.8893 - val_loss: 0.3488 - val_accuracy: 0.8759\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.8907 - val_loss: 0.3491 - val_accuracy: 0.8738\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3031 - accuracy: 0.8906 - val_loss: 0.3438 - val_accuracy: 0.8771\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2982 - accuracy: 0.8919 - val_loss: 0.3502 - val_accuracy: 0.8758\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3002 - accuracy: 0.8916 - val_loss: 0.3405 - val_accuracy: 0.8790\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2945 - accuracy: 0.8932 - val_loss: 0.3399 - val_accuracy: 0.8795\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 0.8932 - val_loss: 0.3432 - val_accuracy: 0.8756\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2949 - accuracy: 0.8932 - val_loss: 0.3410 - val_accuracy: 0.8781\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2927 - accuracy: 0.8929 - val_loss: 0.3367 - val_accuracy: 0.8769\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2884 - accuracy: 0.8950 - val_loss: 0.3319 - val_accuracy: 0.8822\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2880 - accuracy: 0.8964 - val_loss: 0.3445 - val_accuracy: 0.8787\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2872 - accuracy: 0.8957 - val_loss: 0.3367 - val_accuracy: 0.8786\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2856 - accuracy: 0.8965 - val_loss: 0.3363 - val_accuracy: 0.8794\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2825 - accuracy: 0.8980 - val_loss: 0.3367 - val_accuracy: 0.8791\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 0.8977 - val_loss: 0.3312 - val_accuracy: 0.8800\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2823 - accuracy: 0.8974 - val_loss: 0.3418 - val_accuracy: 0.8788\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2787 - accuracy: 0.8983 - val_loss: 0.3309 - val_accuracy: 0.8827\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2757 - accuracy: 0.8999 - val_loss: 0.3339 - val_accuracy: 0.8780\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2810 - accuracy: 0.8962 - val_loss: 0.3360 - val_accuracy: 0.8790\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2726 - accuracy: 0.8999 - val_loss: 0.3249 - val_accuracy: 0.8832\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.9018 - val_loss: 0.3403 - val_accuracy: 0.8769\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.9017 - val_loss: 0.3385 - val_accuracy: 0.8773\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2704 - accuracy: 0.9021 - val_loss: 0.3331 - val_accuracy: 0.8774\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2682 - accuracy: 0.9022 - val_loss: 0.3434 - val_accuracy: 0.8788\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.2706 - accuracy: 0.9012 - val_loss: 0.3289 - val_accuracy: 0.8811\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2641 - accuracy: 0.9036 - val_loss: 0.3214 - val_accuracy: 0.8862\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2608 - accuracy: 0.9052 - val_loss: 0.3213 - val_accuracy: 0.8864\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2619 - accuracy: 0.9043 - val_loss: 0.3337 - val_accuracy: 0.8819\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2636 - accuracy: 0.9033 - val_loss: 0.3257 - val_accuracy: 0.8839\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2598 - accuracy: 0.9047 - val_loss: 0.3181 - val_accuracy: 0.8869\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2581 - accuracy: 0.9057 - val_loss: 0.3231 - val_accuracy: 0.8850\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2548 - accuracy: 0.9079 - val_loss: 0.3219 - val_accuracy: 0.8840\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2536 - accuracy: 0.9087 - val_loss: 0.3179 - val_accuracy: 0.8864\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2526 - accuracy: 0.9085 - val_loss: 0.3322 - val_accuracy: 0.8823\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2528 - accuracy: 0.9073 - val_loss: 0.3255 - val_accuracy: 0.8818\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2545 - accuracy: 0.9070 - val_loss: 0.3201 - val_accuracy: 0.8877\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2493 - accuracy: 0.9094 - val_loss: 0.3225 - val_accuracy: 0.8842\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2535 - accuracy: 0.9079 - val_loss: 0.3147 - val_accuracy: 0.8866\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2460 - accuracy: 0.9107 - val_loss: 0.3212 - val_accuracy: 0.8861\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2498 - accuracy: 0.9075 - val_loss: 0.3125 - val_accuracy: 0.8886\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2441 - accuracy: 0.9112 - val_loss: 0.3142 - val_accuracy: 0.8883\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.9109 - val_loss: 0.3128 - val_accuracy: 0.8874\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3223 - val_accuracy: 0.8866\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2391 - accuracy: 0.9128 - val_loss: 0.3160 - val_accuracy: 0.8884\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2438 - accuracy: 0.9103 - val_loss: 0.3134 - val_accuracy: 0.8875\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2373 - accuracy: 0.9139 - val_loss: 0.3105 - val_accuracy: 0.8912\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2361 - accuracy: 0.9146 - val_loss: 0.3289 - val_accuracy: 0.8831\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2446 - accuracy: 0.9103 - val_loss: 0.3176 - val_accuracy: 0.8857\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.2362 - accuracy: 0.9137 - val_loss: 0.3142 - val_accuracy: 0.8882\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.2378 - accuracy: 0.9122 - val_loss: 0.3120 - val_accuracy: 0.8899\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2323 - accuracy: 0.9157 - val_loss: 0.3192 - val_accuracy: 0.8870\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2334 - accuracy: 0.9145 - val_loss: 0.3115 - val_accuracy: 0.8890\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2292 - accuracy: 0.9163 - val_loss: 0.3226 - val_accuracy: 0.8858\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2276 - accuracy: 0.9170 - val_loss: 0.3106 - val_accuracy: 0.8895\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2269 - accuracy: 0.9173 - val_loss: 0.3125 - val_accuracy: 0.8895\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2302 - accuracy: 0.9157 - val_loss: 0.3120 - val_accuracy: 0.8902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4228657640>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "d5d691d1-ae1f-4ca9-c17b-6a03237361fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "accuracy on train with NN: 0.9169166666666667\n",
            "accuracy on test with NN: 0.8902\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "5289ef8c-c291-441a-be41-499f8897e436",
        "scrolled": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 56ms/step - loss: 0.4519 - accuracy: 0.8529 - val_loss: 0.3377 - val_accuracy: 0.8786\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.3085 - accuracy: 0.8892 - val_loss: 0.3158 - val_accuracy: 0.8848\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.2904 - accuracy: 0.8957 - val_loss: 0.3120 - val_accuracy: 0.8871\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2805 - accuracy: 0.8971 - val_loss: 0.3325 - val_accuracy: 0.8831\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2764 - accuracy: 0.8992 - val_loss: 0.3285 - val_accuracy: 0.8829\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2753 - accuracy: 0.8997 - val_loss: 0.3103 - val_accuracy: 0.8873\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 6s 97ms/step - loss: 0.2676 - accuracy: 0.9020 - val_loss: 0.3151 - val_accuracy: 0.8880\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 4s 73ms/step - loss: 0.2648 - accuracy: 0.9028 - val_loss: 0.3127 - val_accuracy: 0.8878\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 5s 92ms/step - loss: 0.2605 - accuracy: 0.9039 - val_loss: 0.3120 - val_accuracy: 0.8893\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2573 - accuracy: 0.9060 - val_loss: 0.3132 - val_accuracy: 0.8870\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2583 - accuracy: 0.9048 - val_loss: 0.3113 - val_accuracy: 0.8872\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2549 - accuracy: 0.9054 - val_loss: 0.3009 - val_accuracy: 0.8909\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2489 - accuracy: 0.9079 - val_loss: 0.3085 - val_accuracy: 0.8893\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2476 - accuracy: 0.9084 - val_loss: 0.3103 - val_accuracy: 0.8869\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2485 - accuracy: 0.9089 - val_loss: 0.2994 - val_accuracy: 0.8924\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2427 - accuracy: 0.9104 - val_loss: 0.2972 - val_accuracy: 0.8923\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2436 - accuracy: 0.9090 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2417 - accuracy: 0.9101 - val_loss: 0.3058 - val_accuracy: 0.8913\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2423 - accuracy: 0.9099 - val_loss: 0.2961 - val_accuracy: 0.8941\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2403 - accuracy: 0.9107 - val_loss: 0.2981 - val_accuracy: 0.8940\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2364 - accuracy: 0.9122 - val_loss: 0.3036 - val_accuracy: 0.8916\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2348 - accuracy: 0.9127 - val_loss: 0.2986 - val_accuracy: 0.8937\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 4s 65ms/step - loss: 0.2354 - accuracy: 0.9124 - val_loss: 0.3003 - val_accuracy: 0.8938\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2336 - accuracy: 0.9132 - val_loss: 0.2995 - val_accuracy: 0.8920\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2274 - accuracy: 0.9155 - val_loss: 0.2950 - val_accuracy: 0.8930\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2303 - accuracy: 0.9140 - val_loss: 0.3015 - val_accuracy: 0.8901\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2292 - accuracy: 0.9142 - val_loss: 0.2972 - val_accuracy: 0.8957\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2278 - accuracy: 0.9157 - val_loss: 0.2987 - val_accuracy: 0.8924\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2230 - accuracy: 0.9170 - val_loss: 0.2949 - val_accuracy: 0.8939\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2226 - accuracy: 0.9174 - val_loss: 0.2906 - val_accuracy: 0.8966\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2216 - accuracy: 0.9179 - val_loss: 0.2904 - val_accuracy: 0.8959\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2232 - accuracy: 0.9160 - val_loss: 0.2946 - val_accuracy: 0.8959\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2226 - accuracy: 0.9171 - val_loss: 0.2967 - val_accuracy: 0.8946\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 0.2889 - val_accuracy: 0.8973\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2174 - accuracy: 0.9186 - val_loss: 0.3064 - val_accuracy: 0.8925\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.2160 - accuracy: 0.9197 - val_loss: 0.2993 - val_accuracy: 0.8923\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2156 - accuracy: 0.9197 - val_loss: 0.2849 - val_accuracy: 0.8972\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2130 - accuracy: 0.9205 - val_loss: 0.2907 - val_accuracy: 0.8950\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2117 - accuracy: 0.9214 - val_loss: 0.2914 - val_accuracy: 0.8969\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.2111 - accuracy: 0.9208 - val_loss: 0.2883 - val_accuracy: 0.8982\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2075 - accuracy: 0.9231 - val_loss: 0.2869 - val_accuracy: 0.8987\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2095 - accuracy: 0.9223 - val_loss: 0.2837 - val_accuracy: 0.8998\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 3s 60ms/step - loss: 0.2145 - accuracy: 0.9200 - val_loss: 0.2918 - val_accuracy: 0.8961\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2047 - accuracy: 0.9245 - val_loss: 0.2870 - val_accuracy: 0.8993\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2006 - accuracy: 0.9257 - val_loss: 0.2846 - val_accuracy: 0.8991\n",
            "Epoch 46/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2036 - accuracy: 0.9234 - val_loss: 0.2854 - val_accuracy: 0.8981\n",
            "Epoch 47/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2008 - accuracy: 0.9254 - val_loss: 0.2869 - val_accuracy: 0.8998\n",
            "Epoch 48/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2005 - accuracy: 0.9252 - val_loss: 0.2876 - val_accuracy: 0.9018\n",
            "Epoch 49/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.1969 - accuracy: 0.9269 - val_loss: 0.2910 - val_accuracy: 0.8984\n",
            "Epoch 50/100\n",
            "58/58 [==============================] - 4s 60ms/step - loss: 0.1966 - accuracy: 0.9265 - val_loss: 0.2880 - val_accuracy: 0.8990\n",
            "Epoch 51/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.1993 - accuracy: 0.9263 - val_loss: 0.3228 - val_accuracy: 0.8876\n",
            "Epoch 52/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2035 - accuracy: 0.9239 - val_loss: 0.2923 - val_accuracy: 0.8951\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f414a66f940>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "5e4a2b37-ab21-484d-e71c-742a0ad62456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "accuracy on train with NN: 0.92845\n",
            "accuracy on test with NN: 0.8951\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}